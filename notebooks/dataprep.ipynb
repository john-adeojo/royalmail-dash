{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f66ef2f-6d5e-4b3e-8337-ddf8cd427146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f10088-ad74-4969-80d8-512dcd9d0450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afc1c74-6ca5-496e-9aa1-099e6b3135d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(r\"C:\\Users\\johna\\anaconda3\\envs\\royalmail-dash\\royalmail-dash\\data\\01_raw\\tweets_details2023-03-15_20-43-36.csv\")\n",
    "tweets_df = tweets_df.loc[tweets_df['language'] == 'en'].copy()\n",
    "tweets_df = tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0edbe3-1410-4e22-a784-479e84895db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from scripts.data_processing.preprocess_tweets_lite import TextCleaner\n",
    "\n",
    "\n",
    "def get_topics(df, MODEL, model_path):\n",
    "    \n",
    "    _df = df.copy()\n",
    "        \n",
    "\n",
    "    # load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    # Set up tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "    cleaner = TextCleaner(stop_words_remove=False)\n",
    "\n",
    "    _df['cleaned_text'] = _df['text'].apply(cleaner.clean_text)\n",
    "\n",
    "    # set up pipeline\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\", model=model, tokenizer=tokenizer, device=0\n",
    "    )\n",
    "\n",
    "    # perform inference and extract predicted class and probability\n",
    "    results = classifier(list(_df[\"cleaned_text\"]), truncation=True)\n",
    "    \n",
    "    _df[\"topic\"] = [result['label'] for result in results]\n",
    "    _df[\"topic_score\"] = [result['score'] for result in results]\n",
    "    \n",
    "    # Create a new DataFrame with the required columns\n",
    "    output_df = _df[[\"topic\", \"topic_score\", \"cleaned_text\", \"user.location\", \"user.is_blue_verified\", \"favorite_count\", \"retweet_count\", \"reply_count\", \"quote_count\", \"creation_date\"]]\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a4c3e8-3a1a-4cdf-9f42-b98a94cfd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from scripts.data_processing.preprocess_tweets_lite import TextCleaner\n",
    "\n",
    "\n",
    "def get_emotion(df):\n",
    "    \n",
    "    _df = df.copy()\n",
    "            \n",
    "    task='emotion'\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"    \n",
    "\n",
    "    # load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "    # Set up tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "    cleaner = TextCleaner(stop_words_remove=False)\n",
    "\n",
    "    # set up pipeline\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\", model=model, tokenizer=tokenizer, device=0\n",
    "    )\n",
    "\n",
    "    # perform inference and extract predicted class and probability\n",
    "    results = classifier(list(_df[\"cleaned_text\"]), truncation=True)\n",
    "    \n",
    "    _df[\"emotion\"] = [result['label'] for result in results]\n",
    "    _df[\"emotion_score\"] = [result['score'] for result in results]\n",
    "    \n",
    "    return _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8fa198-5b5d-464c-b3c8-010acea01324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "\n",
    "def get_lat_lon(location):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    try:\n",
    "        location_data = geolocator.geocode(location, timeout=10)\n",
    "        if location_data:\n",
    "            return location_data.latitude, location_data.longitude\n",
    "    except GeocoderTimedOut:\n",
    "        return get_lat_lon(location)\n",
    "    return None, None\n",
    "\n",
    "def add_lat_lon_columns(df, location_column):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['coordinates'] = df_copy[location_column].apply(get_lat_lon)\n",
    "    df_copy[['latitude', 'longitude']] = pd.DataFrame(df_copy['coordinates'].tolist(), index=df_copy.index)\n",
    "    df_copy = df_copy.drop(columns=['coordinates'])\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99fcf8a-c007-4234-bbf5-0c9d4b28d2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tweets_dash_data = get_topics(df=tweets_df, MODEL=\"cardiffnlp/twitter-roberta-base\", model_path=r\"C:\\Users\\johna\\OneDrive\\Desktop\\models_twitter_dash\\output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97ac582-98dc-4535-9b3c-f8b9b4762745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tweets_dash_data_2 = get_emotion(df=tweets_dash_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1052f5a9-605a-43c5-8218-12c1020be21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_score</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>user.location</th>\n",
       "      <th>user.is_blue_verified</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_score</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0.955950</td>\n",
       "      <td>You Just got Lawyered by #RoyalMail! ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>On the Corner</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mon Nov 07 10:57:09 +0000 2016</td>\n",
       "      <td>optimism</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>52.048027</td>\n",
       "      <td>-0.023892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0.886760</td>\n",
       "      <td>#RoyalMail advising plebs there's no night shi...</td>\n",
       "      <td>Taxhaven-sur-Mer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mon Sep 12 23:47:42 +0000 2016</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.951047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8813</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0.943916</td>\n",
       "      <td>How fantastic is this! Please get involved and...</td>\n",
       "      <td>East Midlands, England</td>\n",
       "      <td>False</td>\n",
       "      <td>314.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Sat Jul 14 22:56:59 +0000 2018</td>\n",
       "      <td>optimism</td>\n",
       "      <td>0.904597</td>\n",
       "      <td>52.796561</td>\n",
       "      <td>-0.671795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30674</th>\n",
       "      <td>Politics</td>\n",
       "      <td>0.965101</td>\n",
       "      <td>So @darrenpjones How can you call yourself \"im...</td>\n",
       "      <td>Wirral</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Jan 26 18:34:09 +0000 2023</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>53.340971</td>\n",
       "      <td>-3.050092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29707</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0.931512</td>\n",
       "      <td>@karren_brady maybe you should look in to the ...</td>\n",
       "      <td>Wigan, from the Isle of Bute</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sun Dec 11 22:03:11 +0000 2022</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.924056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21340</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0.959240</td>\n",
       "      <td>New \"depot scam\" currently doing the rounds \\n...</td>\n",
       "      <td>Kendal, Cumbria</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mon Feb 15 20:00:01 +0000 2021</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.844457</td>\n",
       "      <td>54.328980</td>\n",
       "      <td>-2.747183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>Sometimes it's the simple things. #postbox #ro...</td>\n",
       "      <td>West Midlands, England</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fri Jan 20 19:28:57 +0000 2017</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>52.505003</td>\n",
       "      <td>-1.964396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>Politics</td>\n",
       "      <td>0.933722</td>\n",
       "      <td>Glad @CWUnews has condemned this apparently se...</td>\n",
       "      <td>Scarborough, England</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu May 17 23:14:14 +0000 2018</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.970610</td>\n",
       "      <td>54.282001</td>\n",
       "      <td>-0.401187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25729</th>\n",
       "      <td>Financial News</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>MARSHALL WACE LLP declares that on March 10 it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fri Mar 11 19:34:23 +0000 2022</td>\n",
       "      <td>optimism</td>\n",
       "      <td>0.402407</td>\n",
       "      <td>46.314475</td>\n",
       "      <td>11.048029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12940</th>\n",
       "      <td>Financial News</td>\n",
       "      <td>0.970900</td>\n",
       "      <td>European Equity Movers this morning: #RoyalMai...</td>\n",
       "      <td>London, England</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mon Jun 17 07:22:16 +0000 2019</td>\n",
       "      <td>optimism</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>51.507336</td>\n",
       "      <td>-0.127650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic  topic_score  \\\n",
       "1349   Customer Service     0.955950   \n",
       "692    Customer Service     0.886760   \n",
       "8813   Customer Service     0.943916   \n",
       "30674          Politics     0.965101   \n",
       "29707  Customer Service     0.931512   \n",
       "21340  Customer Service     0.959240   \n",
       "2330   Customer Service     0.942809   \n",
       "8090           Politics     0.933722   \n",
       "25729    Financial News     0.974386   \n",
       "12940    Financial News     0.970900   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "1349           You Just got Lawyered by #RoyalMail! ðŸ˜‚ðŸ˜‚ðŸ˜‚    \n",
       "692    #RoyalMail advising plebs there's no night shi...   \n",
       "8813   How fantastic is this! Please get involved and...   \n",
       "30674  So @darrenpjones How can you call yourself \"im...   \n",
       "29707  @karren_brady maybe you should look in to the ...   \n",
       "21340  New \"depot scam\" currently doing the rounds \\n...   \n",
       "2330   Sometimes it's the simple things. #postbox #ro...   \n",
       "8090   Glad @CWUnews has condemned this apparently se...   \n",
       "25729  MARSHALL WACE LLP declares that on March 10 it...   \n",
       "12940  European Equity Movers this morning: #RoyalMai...   \n",
       "\n",
       "                      user.location user.is_blue_verified  favorite_count  \\\n",
       "1349                 On the Corner                  False             0.0   \n",
       "692                Taxhaven-sur-Mer                 False             0.0   \n",
       "8813         East Midlands, England                 False           314.0   \n",
       "30674                        Wirral                 False             1.0   \n",
       "29707  Wigan, from the Isle of Bute                 False             0.0   \n",
       "21340               Kendal, Cumbria                 False             1.0   \n",
       "2330         West Midlands, England                 False             0.0   \n",
       "8090           Scarborough, England                 False             0.0   \n",
       "25729                           NaN                 False             0.0   \n",
       "12940               London, England                 False             0.0   \n",
       "\n",
       "       retweet_count  reply_count  quote_count  \\\n",
       "1349             0.0          0.0          1.0   \n",
       "692              0.0          0.0          0.0   \n",
       "8813           326.0         34.0         53.0   \n",
       "30674            0.0          0.0          0.0   \n",
       "29707            0.0          0.0          0.0   \n",
       "21340            1.0          1.0          0.0   \n",
       "2330             0.0          0.0          0.0   \n",
       "8090             0.0          0.0          0.0   \n",
       "25729            0.0          0.0          0.0   \n",
       "12940            0.0          0.0          0.0   \n",
       "\n",
       "                        creation_date   emotion  emotion_score   latitude  \\\n",
       "1349   Mon Nov 07 10:57:09 +0000 2016  optimism       0.537400  52.048027   \n",
       "692    Mon Sep 12 23:47:42 +0000 2016       joy       0.951047        NaN   \n",
       "8813   Sat Jul 14 22:56:59 +0000 2018  optimism       0.904597  52.796561   \n",
       "30674  Thu Jan 26 18:34:09 +0000 2023       joy       0.969231  53.340971   \n",
       "29707  Sun Dec 11 22:03:11 +0000 2022       joy       0.924056        NaN   \n",
       "21340  Mon Feb 15 20:00:01 +0000 2021       joy       0.844457  54.328980   \n",
       "2330   Fri Jan 20 19:28:57 +0000 2017   sadness       0.383989  52.505003   \n",
       "8090   Thu May 17 23:14:14 +0000 2018       joy       0.970610  54.282001   \n",
       "25729  Fri Mar 11 19:34:23 +0000 2022  optimism       0.402407  46.314475   \n",
       "12940  Mon Jun 17 07:22:16 +0000 2019  optimism       0.662903  51.507336   \n",
       "\n",
       "       longitude  \n",
       "1349   -0.023892  \n",
       "692          NaN  \n",
       "8813   -0.671795  \n",
       "30674  -3.050092  \n",
       "29707        NaN  \n",
       "21340  -2.747183  \n",
       "2330   -1.964396  \n",
       "8090   -0.401187  \n",
       "25729  11.048029  \n",
       "12940  -0.127650  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dash_final = add_lat_lon_columns(tweets_dash_data_2, 'user.location')\n",
    "tweets_dash_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3163e3-5ceb-46a3-ba6b-fd04d5407df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tweets_dash_final.to_csv(r\"C:\\Users\\johna\\anaconda3\\envs\\royalmail-dash\\royalmail-dash\\data\\02_intermediate\\tweets_dash.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
